# Cilium Service Mesh - Bootstrap Integration Guide

**Date:** 2025-10-15
**Architecture:** Cilium 1.18.x Service Mesh via Helmfile Bootstrap

---

## üéØ Overview

Your infrastructure deploys **Cilium with full service mesh features** via the bootstrap helmfile. This guide explains what was configured and how to use it.

### Why Bootstrap (Not Flux)?

Cilium is your **CNI** - the networking foundation. It must be deployed BEFORE Flux, since Flux needs networking to function. The bootstrap sequence is:

```
1. Talos boots ‚Üí 2. Helmfile deploys Cilium ‚Üí 3. Networking works ‚Üí 4. Flux deploys everything else
```

---

## üìÅ Configuration Files

### Bootstrap Configuration

```
bootstrap/
‚îú‚îÄ‚îÄ helmfile.d/
‚îÇ   ‚îî‚îÄ‚îÄ 01-core.yaml              # Orchestrates Cilium deployment
‚îî‚îÄ‚îÄ clusters/
    ‚îú‚îÄ‚îÄ infra/
    ‚îÇ   ‚îú‚îÄ‚îÄ values.yaml           # Infra cluster settings
    ‚îÇ   ‚îî‚îÄ‚îÄ cilium-values.yaml    # ‚ú® Cilium service mesh config (infra)
    ‚îî‚îÄ‚îÄ apps/
        ‚îú‚îÄ‚îÄ values.yaml           # Apps cluster settings
        ‚îî‚îÄ‚îÄ cilium-values.yaml    # ‚ú® Cilium service mesh config (apps)
```

### What Changed

**File: `bootstrap/helmfile.d/01-core.yaml`**
```yaml
# BEFORE (basic Cilium):
version: 1.18.2  # Pinned version
values: [minimal inline config]

# AFTER (service mesh):
version: ">=1.18.0 <1.19.0"  # Semantic versioning
values:
  - ../clusters/{{ .Environment.Name }}/cilium-values.yaml  # Full config
```

**New Files:**
- `bootstrap/clusters/infra/cilium-values.yaml` - 300+ lines of service mesh config
- `bootstrap/clusters/apps/cilium-values.yaml` - Same, with different cluster ID/CIDR

---

## ‚ú® Service Mesh Features Enabled

Your Cilium deployment now includes:

### 1. **WireGuard Encryption** (Transparent mTLS)
- ‚úÖ All pod-to-pod traffic automatically encrypted
- ‚úÖ Zero application changes required
- ‚úÖ Kernel-level performance

```yaml
encryption:
  enabled: true
  type: wireguard
```

### 2. **SPIRE Workload Identity**
- ‚úÖ Cryptographic identity for each workload
- ‚úÖ Enables identity-based L7 policies
- ‚úÖ Automatic certificate rotation

```yaml
authentication:
  enabled: true
  mutual:
    spire:
      enabled: true
```

### 3. **Hubble Observability**
- ‚úÖ L7 protocol awareness (HTTP, gRPC, DNS, Kafka, etc.)
- ‚úÖ Service dependency maps
- ‚úÖ Golden metrics (success rate, RPS, latency)
- ‚úÖ Real-time flow visualization

```yaml
hubble:
  enabled: true
  relay:
    enabled: true  # Cluster-wide aggregation
  ui:
    enabled: true  # Web-based service map
```

### 4. **Cluster Mesh** (Multi-Cluster)
- ‚úÖ Cross-cluster service discovery
- ‚úÖ Encrypted tunnels between clusters
- ‚úÖ Global service load balancing
- ‚úÖ No separate gateway pods needed

```yaml
clustermesh:
  useAPIServer: true
  apiserver:
    replicas: 2
    service:
      type: LoadBalancer
```

### 5. **BGP Control Plane**
- ‚úÖ Native BGP support for advanced routing
- ‚úÖ Integrates with your network infrastructure

```yaml
bgpControlPlane:
  enabled: true
```

### 6. **Gateway API**
- ‚úÖ Modern ingress/egress management
- ‚úÖ Replaces Ingress resources

```yaml
gatewayAPI:
  enabled: true
```

---

## üöÄ Deployment

### First-Time Bootstrap

```bash
# Bootstrap infra cluster with Cilium service mesh
task bootstrap:infra

# Bootstrap apps cluster
task bootstrap:apps

# Verify Cilium deployment
cilium status --wait --context infra
cilium status --wait --context apps
```

### Verify Service Mesh Features

```bash
# 1. Check kube-proxy replacement (service mesh enabled)
cilium status --context infra | grep KubeProxyReplacement
# Expected: KubeProxyReplacement:    True

# 2. Verify encryption
cilium encrypt status --context infra
# Expected: WireGuard keys and tunnels

# 3. Check Hubble
hubble status --context infra
# Expected: Healthcheck (via localhost:4245): Ok

# 4. View live flows
hubble observe --namespace kube-system --context infra

# 5. Launch Hubble UI
cilium hubble ui --context infra
# Opens http://localhost:12000
```

---

## üåê Multi-Cluster Setup (Week 3)

After both clusters are bootstrapped, connect them via Cluster Mesh:

```bash
# Enable Cluster Mesh (creates API servers)
cilium clustermesh enable --context infra --service-type LoadBalancer
cilium clustermesh enable --context apps --service-type LoadBalancer

# Connect clusters
cilium clustermesh connect --context apps --destination-context infra

# Verify connection
cilium clustermesh status --context apps
# Expected: ‚úÖ infra: reachable, ready

# Export services from infra cluster
kubectl annotate svc/<service-name> -n <namespace> \
  io.cilium/global-service="true" \
  --context infra

# Access from apps cluster
# Service is available via standard DNS:
# <service-name>.<namespace>.svc.cluster.local
```

---

## üìä Observability Stack

### Hubble CLI

```bash
# View all flows
hubble observe --context infra

# Specific namespace
hubble observe --namespace gitlab --context apps

# HTTP traffic only
hubble observe --protocol http --context apps

# Dropped packets (policy violations)
hubble observe --verdict DROPPED --context apps

# Cross-cluster traffic
hubble observe \
  --from-namespace gitlab \
  --to-namespace databases \
  --context apps
```

### Hubble UI

```bash
# Launch UI
cilium hubble ui --context infra

# Features:
# - Service dependency map
# - Real-time flow visualization
# - Protocol-aware inspection
# - Policy enforcement visualization
```

### Metrics

Hubble exports Prometheus metrics automatically scraped by Victoria Metrics:

```promql
# HTTP request rate
sum(rate(hubble_http_requests_total[5m])) by (namespace, pod)

# Success rate
sum(rate(hubble_http_requests_total{code=~"2.."}[5m]))
  /
sum(rate(hubble_http_requests_total[5m]))

# Dropped packets
sum(rate(hubble_drop_total[5m])) by (reason)
```

### Distributed Tracing (Week 3)

After deploying Jaeger, enable Hubble ‚Üí Jaeger export:

```yaml
# Edit bootstrap/clusters/infra/cilium-values.yaml
hubble:
  export:
    dynamic:
      enabled: true  # Change from false
      config:
        configMapName: hubble-export-config
```

Then create the ConfigMap:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: hubble-export-config
  namespace: kube-system
data:
  config.yaml: |
    exports:
    - name: jaeger-otel
      dynamic:
        type: otel
        config:
          address: jaeger-collector.observability.svc.cluster.local:4317
          retryInterval: 30s
          exportInterval: 30s
```

```bash
# Re-run bootstrap to apply changes
task bootstrap:infra

# Restart Cilium pods
kubectl rollout restart daemonset/cilium -n kube-system --context infra
```

---

## üîß Modifying Configuration

### Update Cilium Settings

```bash
# 1. Edit configuration
vim bootstrap/clusters/infra/cilium-values.yaml
# or
vim bootstrap/clusters/apps/cilium-values.yaml

# 2. Re-run bootstrap
task bootstrap:infra
# or
task bootstrap:apps

# 3. Verify changes
cilium status --context infra
```

### Common Modifications

**Enable host firewall:**
```yaml
hostFirewall:
  enabled: true
```

**Adjust resource limits:**
```yaml
resources:
  requests:
    cpu: 300m      # Increase if needed
    memory: 768Mi
  limits:
    cpu: 2000m
    memory: 4Gi
```

**Tune BPF map sizes:**
```yaml
bpf:
  ctTcpMax: 1048576  # Double for large clusters
  natMax: 1048576
```

---

## üìà Resource Usage

**Per Cluster:**
```
Cilium Overhead:
‚îú‚îÄ Operator (2 replicas): 200m CPU, 256 MB RAM
‚îú‚îÄ Agents (DaemonSet): 200m CPU √ó nodes, 512 MB RAM √ó nodes
‚îú‚îÄ Hubble Relay: 100m CPU, 128 MB RAM
‚îú‚îÄ Hubble UI: 50m CPU, 64 MB RAM
‚îú‚îÄ Cluster Mesh API: 200m CPU, 256 MB RAM
‚îî‚îÄ SPIRE: 100m CPU, 128 MB RAM

Total (3-node cluster): ~1.5 CPU, ~3 GB RAM
```

**No sidecars** - all traffic handled at kernel level (eBPF), not per-pod proxies.

---

## üÜö Comparison: Your Architecture vs Alternatives

| Aspect | Your Setup (Cilium Bootstrap) | Linkerd (Rejected) |
|--------|------------------------------|-------------------|
| **Deployment** | ‚úÖ Helmfile bootstrap | ‚ùå CLI-based |
| **GitOps** | ‚úÖ Configuration in Git | ‚ö†Ô∏è Complex GitOps |
| **Version Management** | ‚úÖ Semantic versioning | ‚ùå Pinned versions |
| **Resource Overhead** | ‚úÖ ~1.5 CPU/cluster | ‚ùå ~6.9 CPU/cluster |
| **Sidecars** | ‚úÖ None (eBPF) | ‚ùå One per pod |
| **Multi-Cluster** | ‚úÖ Cluster Mesh (mature) | ‚ö†Ô∏è Service mirroring (newer) |
| **Observability** | ‚úÖ Hubble (L7 aware) | ‚úÖ Linkerd Viz (L7 aware) |
| **Encryption** | ‚úÖ WireGuard (kernel) | ‚úÖ Proxy mTLS |

---

## üêõ Troubleshooting

### Cilium Not Starting

```bash
# Check pod status
kubectl get pods -n kube-system -l k8s-app=cilium --context infra

# Check logs
kubectl logs -n kube-system -l k8s-app=cilium --context infra --tail=50

# Common issues:
# 1. Kernel version too old (need 4.9.17+)
# 2. SELinux blocking (Talos doesn't have this)
# 3. Previous CNI remnants (Talos uses cni: none so no issue)
```

### Encryption Not Working

```bash
# Verify WireGuard module
kubectl exec -n kube-system ds/cilium --context infra -- lsmod | grep wireguard

# If missing, check Talos kernel (should include WireGuard)
talosctl get members --context infra

# Check encryption status
cilium encrypt status --context infra
```

### Hubble Not Showing Flows

```bash
# Check Hubble relay
kubectl get pods -n kube-system -l k8s-app=hubble-relay --context infra

# Restart if needed
kubectl rollout restart deployment/hubble-relay -n kube-system --context infra

# Check hubble status
hubble status --context infra

# If "connection refused", port-forward manually:
cilium hubble port-forward --context infra
```

### Cluster Mesh Not Connecting

```bash
# Check API server status
kubectl get pods -n kube-system -l k8s-app=clustermesh-apiserver --context infra

# Verify LoadBalancer service
kubectl get svc clustermesh-apiserver -n kube-system --context infra
# Should have EXTERNAL-IP

# Check connectivity
cilium clustermesh status --verbose --context apps

# Common fix: Re-establish connection
cilium clustermesh disconnect --context apps --destination-context infra
cilium clustermesh connect --context apps --destination-context infra
```

---

## üìö Next Steps

### Week 1-2 (Now): Foundation ‚úÖ

- [x] Cilium deployed with service mesh features
- [x] Hubble observability enabled
- [x] Encryption active (WireGuard)
- [x] SPIRE identity enabled
- [ ] Deploy Victoria Metrics (for Hubble metrics)

### Week 3: Multi-Cluster

- [ ] Enable Cluster Mesh on both clusters
- [ ] Connect infra ‚Üî apps clusters
- [ ] Deploy Jaeger for distributed tracing
- [ ] Enable Hubble ‚Üí Jaeger export
- [ ] Test cross-cluster service discovery

### Week 4+: Platform Services

- [ ] Deploy CloudNativePG (infra cluster)
- [ ] Export database services via Cluster Mesh
- [ ] Deploy applications (apps cluster)
- [ ] Validate cross-cluster communication
- [ ] Implement Cilium Network Policies

---

## üìñ Reference Documentation

- **Your Cilium Config:** `bootstrap/clusters/{infra,apps}/cilium-values.yaml`
- **Cilium Docs:** https://docs.cilium.io/
- **Cluster Mesh:** https://docs.cilium.io/en/stable/network/clustermesh/
- **Hubble:** https://docs.cilium.io/en/stable/observability/hubble/
- **Detailed Observability Guide:** `docs/hubble-observability-guide.md`
- **Full Implementation Plan:** `docs/cilium-service-mesh-implementation-plan.md`

---

## ‚úÖ Success Metrics

After deployment, you should see:

```bash
# All checks pass
cilium status --context infra

# Output shows:
#     /¬Ø¬Ø\
#  /¬Ø¬Ø\__/¬Ø¬Ø\    Cilium:             OK
#  \__/¬Ø¬Ø\__/    Operator:           OK
#  /¬Ø¬Ø\__/¬Ø¬Ø\    Hubble Relay:       OK
#  \__/¬Ø¬Ø\__/    ClusterMesh:        OK
#     \__/       Encryption:         Wireguard [cilium_wg0]
#
# KubeProxyReplacement:  True
# Encryption:            Wireguard
```

**You're ready for Week 3: Multi-Cluster Service Mesh!** üöÄ

---

*Generated: 2025-10-15*
*Architecture: Cilium 1.18.x Service Mesh on Talos Linux*
*Deployment Method: Helmfile Bootstrap ‚Üí Flux GitOps*
